{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(m_str='bert-base-uncased'):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # has limit of 512 sequence length\n",
    "    model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "    model.eval()\n",
    "    model = model.to('cuda')\n",
    "    return model\n",
    "\n",
    "def load_tokenizer(t_str=\"bert-base-uncased\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(t_str)\n",
    "    return tokenizer\n",
    "\n",
    "def tokenize_bert(text_batch,tokenizer):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    tokenized_tensor = torch.LongTensor([tokenizer.encode(text,\n",
    "                                                          truncation=True,\n",
    "                                                          padding=\"max_length\",\n",
    "                                                          max_length=500, \n",
    "                                                          add_special_tokens=True)  # Add [CLS] and [SEP],) \n",
    "                                                          for text in text_batch])\n",
    "    tokenized_tensor = tokenized_tensor.to('cuda')\n",
    "    return tokenized_tensor\n",
    "        \n",
    "def batch_text_gen(text_list,batch_size=500):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    for ndx in range(0,len(text_list),batch_size):\n",
    "        yield text_list[ndx:min(ndx+batch_size,len(text_list))]\n",
    "\n",
    "@timer\n",
    "def infer_embeddings(text_list,\n",
    "                     batch_size=50,\n",
    "                     save_folder_1=\"/media/karthikshivaram/Extra_disk_1/Bert_model_outputs\",\n",
    "                     save_folder_2=\"/media/karthikshivaram/Extra_Disk_2/Bert_model_outputs\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # 512 token limit\n",
    "    \n",
    "    model = load_model()\n",
    "    tokenizer = load_tokenizer()\n",
    "    num_batches = int(len(text_list)/batch_size)\n",
    "    print(\"Number of Batches : %s\\n\"%str(num_batches))\n",
    "    batches_sf1 = 0\n",
    "    batches_sf2 = 0\n",
    "    with torch.no_grad():\n",
    "        batch_no = 0\n",
    "        for text_batch in batch_text_gen(text_list,batch_size):\n",
    "            if batch_no > 0 and batch_no % 100 == 0:\n",
    "                print(\"Running Batch : %s\"%str(batch_no))\n",
    "            batch_tensor = tokenize_bert(text_batch,tokenizer)\n",
    "            batch_out = model(input_ids=batch_tensor)\n",
    "            batch_hidden_states = batch_out[2]\n",
    "            batch_all_layer_tensor = torch.cat(batch_hidden_states[1:],2)\n",
    "            \n",
    "            if batch_no == 0:\n",
    "                print(batch_all_layer_tensor.size())\n",
    "            \n",
    "            if batch_no < int(num_batches/2):\n",
    "                np.save(\"%s/%s.npy\"%(save_folder_1,str(batch_no)),batch_all_layer_tensor.cpu().numpy())\n",
    "                batches_sf1 +=1\n",
    "                    \n",
    "            else:\n",
    "                np.save(\"%s/%s.npy\"%(save_folder_2,str(batch_no)),batch_all_layer_tensor.cpu().numpy())\n",
    "                batches_sf2 +=1\n",
    "                \n",
    "            batch_no +=1\n",
    "    \n",
    "    print(\"\\nTotal Batches Saved : %s\" %str(batch_no))\n",
    "    print(\"Batches saved to : %s    \\n%s\"%(save_folder_1,str(batches_sf1)))\n",
    "    print(\"Batches saved to : %s    \\n%s\"%(save_folder_2,str(batches_sf2)))\n",
    "\n",
    "def load_bert_embeddings(folder=\"Bert_embed_files\"):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    files = os.listdir(folder)\n",
    "    files = sorted(files,key=lambda x: int(x.split(\".\")[0]),reverse=False)\n",
    "    print(files[:10])\n",
    "    batch_list_arrs = []\n",
    "    for f in files:\n",
    "        loaded_tensor = torch.load(folder+os.path.sep+f).numpy()\n",
    "        batch_list_arrs.append(loaded_tensor)\n",
    "    \n",
    "    return np.concatenate(batch_list_arrs,axis=0)\n",
    "        \n",
    "\n",
    "def infer_embed_test():\n",
    "    \"\"\"\n",
    "    Notes:\n",
    "    * Number of hidden states is 13 why ?\n",
    "    * output of the embeddings + one for the output of each layer (12)\n",
    "    * output of the embeddings is the vector that's fed into the first layer of bert\n",
    "    * output of the embedding = sum of the token embeddings + the segment embeddings + the position embeddings.\n",
    "    \n",
    "    Reference : https://github.com/huggingface/transformers/issues/2332\n",
    "    \"\"\"\n",
    "    model = load_model()\n",
    "    tokenizer = load_tokenizer()\n",
    "    with torch.no_grad():\n",
    "        test_sent = \"this is a test\"\n",
    "        test_sent2 = \"this is another test\"\n",
    "        tokenized_sent = torch.LongTensor([tokenizer.encode(test,\n",
    "                                                           add_special_tokens=True,  # Add [CLS] and [SEP],\n",
    "                                                           max_length = 10,  # maximum length of a sentence\n",
    "                                                           padding=\"max_length\",  # Add [PAD]s\n",
    "                                                           truncation=True) for test in [test_sent,test_sent2]])\n",
    "        \n",
    "        print(\"tokenized output size : %s\" %str(tokenized_sent.size()))\n",
    "        print(\"tokenized output ids : \\n%s\" %str(tokenized_sent))\n",
    "        print(\"tokenized output tokens : \\n%s\"%str(tokenizer.convert_ids_to_tokens(tokenized_sent[0])))\n",
    "        tokenized_tensor = tokenized_sent.to(\"cuda\")\n",
    "        out = model(input_ids=tokenized_tensor)\n",
    "        print(\"\\nOutput Type : \\n%s\"%str(type(out)) )\n",
    "        print(\"\\nOutput Attr : \\n%s\"%str(out.__dict__.keys()))\n",
    "        print(\"\\nHidden States Type : \\n%s\"%str(type(out[2])))\n",
    "        print(\"\\nHidden States Length : \\n%s\"%str(len(out[2])))\n",
    "        for i,n in enumerate(out[2]):\n",
    "            print(\"Layer %s Hidden State size : %s\" %(str(i),str(n.size())))\n",
    "        \n",
    "        print(\"\\nPickle Test :\")\n",
    "        print(\"\\nSaving Hidden State tuple as Pickle\")\n",
    "        with open(\"bert_pickle_hs_test.pkl\",'wb') as bw:\n",
    "            pickle.dump(out[2][1:],bw)\n",
    "        print(\"Finished Saving\")\n",
    "        print(\"\\nLoading Hidden State tuple from Pickle File\")\n",
    "        loaded_hs = None\n",
    "        with open(\"bert_pickle_hs_test.pkl\",\"rb\") as br:\n",
    "            loaded_hs = pickle.load(br)\n",
    "        print(\"Finished Loading\")\n",
    "        print(\"\\nLoaded Type : %s\" %str(type(loaded_hs)))\n",
    "        print(\"Loaded Size : %s\" %str(len(loaded_hs)))\n",
    "        print(\"Layer 1 Embedding Size : %s\"%str(loaded_hs[0].size()))\n",
    "        print(\"All Layer concatenation size : %s\" %str(torch.cat(loaded_hs,2).size()))\n",
    "        print(\"Numpy Version :\\n%s\" %str(loaded_hs[0].cpu().numpy()))\n",
    "\n",
    "@timer\n",
    "def load_bert_output(folder1=\"/media/karthikshivaram/Extra_disk_1/Bert_model_outputs\",\n",
    "                     folder2=\"/media/karthikshivaram/Extra_Disk_2/Bert_model_outputs\",\n",
    "                     layer=12,\n",
    "                     aggregation=\"mean\"):\n",
    "    \"\"\"\n",
    "    Loads the bert hidden state tuple from saved pickle file and performs aggregation\n",
    "    to get the sentence vector and then combines the batch output to generate one overall \n",
    "    matrix of vectorized sentences.\n",
    "    \n",
    "    aggregation types:\n",
    "    * max\n",
    "    * mean\n",
    "    * mean + max\n",
    "    * cls (pick first out of all)\n",
    "    * last 4 concat (concatenate last 4 layers) (This ignores layers argument)\n",
    "    \n",
    "    Parameters:\n",
    "    * folder -> path of saved pickle files of bert output\n",
    "    * layer -> int , the layer to extract representation from\n",
    "    * aggregation -> str, the aggregation method to perform to convert token embeddings to sentence embeddings\n",
    "    \"\"\"\n",
    "    batch_outputs = []\n",
    "    \n",
    "    layers_start = [i* 768  for i in range(12)]\n",
    "    layers_stop = [i+768 for i in layers_start]\n",
    "    \n",
    "    def get_batch_arr(file,layer):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        batch_arr = np.load(f)\n",
    "        # 3d matrix [batch_size,max_length,all_12_layer_output (12*768)]\n",
    "        layer_slice_start = layers_start[layer-1]\n",
    "        layer_slice_stop = layers_stop[layer-1]\n",
    "        # get [batch_size,max_length,layer_output(768)]\n",
    "        batch_layer_slice = batch_arr[:,:,layer_slice_start:layer_slice_stop]\n",
    "        return batch_layer_slice\n",
    "    \n",
    "    def get_cls_rep(file,layer,token_index=0):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        batch_arr = np.load(f)\n",
    "        layer_slice_start = layers_start[layer-1]\n",
    "        layer_slice_stop = layers_stop[layer-1]\n",
    "        # get [batch_size,max_length,layer_output(768)]\n",
    "        batch_layer_slice = batch_arr[:,0,layer_slice_start:layer_slice_stop]\n",
    "        return batch_layer_slice\n",
    "    \n",
    "    def get_max(batch_layer_slice):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        batch_agg_arr = np.max(batch_layer_slice,axis=1)\n",
    "        return batch_agg_arr\n",
    "    \n",
    "    def get_mean(batch_layer_slice):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        batch_agg_arr = np.mean(batch_layer_slice,axis=1)\n",
    "        return batch_agg_arr\n",
    "    \n",
    "    files1 = os.listdir(folder1)\n",
    "    files1 = [folder1 + os.path.sep+f for f in files1]\n",
    "    files2 = os.listdir(folder2)\n",
    "    files2 = [folder2 + os.path.sep+f for f in files2]\n",
    "    files = files1 + files2\n",
    "    files = sorted(files,key=lambda x: int(x.split(os.path.sep)[-1].split(\".\")[0]),reverse=False)\n",
    "    print(\"First Ten Files : %s\" %str(files[:10]))\n",
    "    \n",
    "    for f in files:\n",
    "        \n",
    "        if aggregation == \"max\":\n",
    "            batch_layer_slice = get_batch_arr(file=f,layer=layer)\n",
    "            # mean over max_length axis\n",
    "            batch_agg_arr = get_max(batch_layer_slice)\n",
    "            batch_outputs.append(batch_agg_arr)\n",
    "        \n",
    "        if aggregation == \"mean\":\n",
    "            batch_layer_slice = get_batch_arr(file=f,layer=layer)\n",
    "            # mean over max_length axis\n",
    "            batch_agg_arr = get_mean(batch_layer_slice)\n",
    "            batch_outputs.append(batch_agg_arr)\n",
    "        \n",
    "        if aggregation == \"mean + max\":\n",
    "            batch_layer_slice = get_batch_arr(file=f,layer=layer)\n",
    "            batch_agg_arr_max = get_max(batch_layer_slice)\n",
    "            batch_agg_arr_mean = get_mean(batch_layer_slice)\n",
    "            batch_outputs.append(np.concat([batch_agg_arr_mean,batch_agg_arr_max],axis=1))\n",
    "        \n",
    "        if aggregation == \"cls\":\n",
    "            batch_layer_slice = get_cls_rep(file=f,layer=layer,token_index=0)\n",
    "            batch_outputs.append(batch_layer_slice)\n",
    "            \n",
    "        if aggregation == \"last 4 concat\":\n",
    "            pass\n",
    "    \n",
    "    return np.concatenate(batch_outputs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized output size : torch.Size([2, 10])\n",
      "tokenized output ids : \n",
      "tensor([[ 101, 2023, 2003, 1037, 3231,  102,    0,    0,    0,    0],\n",
      "        [ 101, 2023, 2003, 2178, 3231,  102,    0,    0,    0,    0]])\n",
      "tokenized output tokens : \n",
      "['[CLS]', 'this', 'is', 'a', 'test', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "\n",
      "Output Type : \n",
      "<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>\n",
      "\n",
      "Output Attr : \n",
      "dict_keys(['last_hidden_state', 'pooler_output', 'hidden_states', 'past_key_values', 'attentions', 'cross_attentions'])\n",
      "\n",
      "Hidden States Type : \n",
      "<class 'tuple'>\n",
      "\n",
      "Hidden States Length : \n",
      "13\n",
      "Layer 0 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 1 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 2 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 3 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 4 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 5 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 6 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 7 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 8 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 9 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 10 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 11 Hidden State size : torch.Size([2, 10, 768])\n",
      "Layer 12 Hidden State size : torch.Size([2, 10, 768])\n",
      "\n",
      "Pickle Test :\n",
      "\n",
      "Saving Hidden State tuple as Pickle\n",
      "Finished Saving\n",
      "\n",
      "Loading Hidden State tuple from Pickle File\n",
      "Finished Loading\n",
      "\n",
      "Loaded Type : <class 'tuple'>\n",
      "Loaded Size : 12\n",
      "Layer 1 Embedding Size : torch.Size([2, 10, 768])\n",
      "All Layer concatenation size : torch.Size([2, 10, 9216])\n",
      "Numpy Version :\n",
      "[[[ 0.17634596 -0.03861757 -0.05701372 ...  0.09617269  0.03604349\n",
      "    0.05073412]\n",
      "  [-0.88817126  0.37663308 -0.15377447 ...  0.03870337  0.35127684\n",
      "    0.17864107]\n",
      "  [-1.325414   -0.6237455  -0.6481573  ...  0.17615855  0.34011704\n",
      "    0.56191665]\n",
      "  ...\n",
      "  [ 0.21647128 -0.6118047  -0.01224619 ...  0.1016796   0.22659111\n",
      "   -0.08523327]\n",
      "  [ 0.23043644 -0.5654165  -0.07813594 ...  0.19184548  0.14501789\n",
      "   -0.04127939]\n",
      "  [ 0.36409593 -0.32220426 -0.15476571 ...  0.3014999  -0.11021291\n",
      "   -0.00883756]]\n",
      "\n",
      " [[ 0.13732909 -0.07618455 -0.03415141 ...  0.07418928  0.027657\n",
      "    0.01901989]\n",
      "  [-0.8534905   0.38412008 -0.09443363 ...  0.00772762  0.38458276\n",
      "    0.17634353]\n",
      "  [-1.3263116  -0.6406678  -0.6051302  ...  0.2340211   0.3944876\n",
      "    0.5366863 ]\n",
      "  ...\n",
      "  [ 0.20464261 -0.61921084  0.00157411 ...  0.10895532  0.22157745\n",
      "   -0.08195122]\n",
      "  [ 0.22069004 -0.5715266  -0.06499861 ...  0.1973679   0.14288463\n",
      "   -0.03828818]\n",
      "  [ 0.35628444 -0.33012447 -0.1448437  ...  0.30505437 -0.11119313\n",
      "   -0.00364357]]]\n"
     ]
    }
   ],
   "source": [
    "infer_embed_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1,10,768"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Frames",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
